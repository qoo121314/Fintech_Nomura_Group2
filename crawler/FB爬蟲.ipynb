{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME='\n",
    "PASSWORD='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# profile = webdriver.ChromeProfile() # 新增firefox的設定\n",
    "# profile.set_preference(\"dom.webnotifications.enabled\", False) # 將頁面通知關掉\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.facebook.com\")\n",
    "time.sleep(3)\n",
    "driver.find_element_by_id(\"email\").send_keys(USERNAME) # 將USERNAME改為你的臉書帳號\n",
    "driver.find_element_by_id(\"pass\").send_keys(PASSWORD) # 將PASSWORD改為你的臉書密碼\n",
    "driver.find_element_by_id(\"loginbutton\").click()\n",
    "time.sleep(3)\n",
    "driver.get('https://www.facebook.com/groups/1517250658578705/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12): # 捲動12次\n",
    "    driver.execute_script(\"window.scrollTo(0, {})\".format(4000 * (i + 1))) #每次捲動4000的單位\n",
    "    time.sleep(2) # 等待2秒鐘讓頁面讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClickForMore():\n",
    "    hrefBtns = driver.find_elements_by_tag_name('a')    \n",
    "    for btn in hrefBtns:\n",
    "        try:\n",
    "            s = btn.get_attribute('data-testid')\n",
    "        except:\n",
    "            continue\n",
    "        if s == 'UFI2CommentsPagerRenderer/pager_depth_1' or s == 'UFI2CommentsPagerRenderer/pager_depth_0':\n",
    "            try:\n",
    "                btn.click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                continue\n",
    "ClickForMore()\n",
    "ClickForMore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "htmltext = driver.page_source # 將網頁原始碼拿出來\n",
    "\n",
    "\n",
    "def parse_htmltext(htmltext, start_date, end_date):\n",
    "    '''\n",
    "    解析臉書貼文與回覆的原始碼。\n",
    "    htmltext為原始碼，str\n",
    "    star_date為起始日期，datetime.datetime\n",
    "    end_date為結束日期，datetime.datetime\n",
    "    '''   \n",
    "    post_persons = []\n",
    "    comment_persons = []\n",
    "    good_urllist = [] # 回復表情符號超連結\n",
    "    ustart_date = start_date.timestamp()\n",
    "    uend_date = end_date.timestamp()\n",
    "    soup = BeautifulSoup(htmltext, 'html.parser')\n",
    "    body = soup.find('body')\n",
    "    posts = body.select('div[id=\"pagelet_group_mall\"]')[0].select('div[aria-label=\"動態消息\"]')[0]\n",
    "    feed_articles = posts.select('div[role=\"feed\"]')[0].select('div[role=\"article\"]')\n",
    "    other_articles = posts.select('div[role=\"article\"]')\n",
    "    articles = feed_articles + other_articles # 所有貼文或留言\n",
    "    \n",
    "    for article in articles:\n",
    "        if article.has_attr('id'):\n",
    "            try:\n",
    "                post_person = re.findall('title=\"(.{2,20})\"><div class=', str(article))[0]\n",
    "            except:\n",
    "                continue\n",
    "            post_time = int(re.findall('data-utime=\"(.*?)\"', str(article))[0])        \n",
    "            if post_time >= ustart_date and post_time <= uend_date:                \n",
    "                post_persons.append(post_person)\n",
    "            try:\n",
    "                good_urllist.append(re.findall('\"(/ufi/reaction/profile/browser/\\?.*?)\"', str(article))[0])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        elif article.has_attr('data-testid'):            \n",
    "            comment_person = re.findall('directed_target_id.*?href=\".*?\">(.*?)</a>', str(article))[0]  \n",
    "            comment_time = int(re.findall('data-utime=\"(.*?)\"', str(article))[0])\n",
    "            if comment_time >= ustart_date and post_time <= uend_date:                    \n",
    "                comment_persons.append(comment_person)                    \n",
    "                try:\n",
    "                    good_urllist.append(re.findall('\"(/ufi/reaction/profile/browser/\\?.*?)\"', str(article))[0])\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return post_persons, comment_persons, good_urllist\n",
    "\n",
    "post_persons, comment_persons, good_urllist = parse_htmltext(htmltext, datetime.datetime(2020, 3, 25), datetime.datetime(2020, 3, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wen Hua Yen',\n",
       " 'Wen Hua Yen',\n",
       " 'Yung Chnu',\n",
       " 'Mei Ling',\n",
       " 'Daniel Wse',\n",
       " 'Richard Wang',\n",
       " 'Yi L',\n",
       " 'Ray Hsiao',\n",
       " 'Feng Liu',\n",
       " '藍小雨',\n",
       " 'Gary Lai',\n",
       " 'Damon Wu',\n",
       " '若凡',\n",
       " '陳佩蓉',\n",
       " '呂郁青',\n",
       " '洪柏璋',\n",
       " '錢宗右',\n",
       " 'Ray Hsiao',\n",
       " 'Yung Chnu',\n",
       " '陳佐',\n",
       " '鄭瑪答',\n",
       " 'Jennifer Pai',\n",
       " 'Dan Chen',\n",
       " 'Kevin Chen',\n",
       " 'Moni Ho',\n",
       " '郭軒旻',\n",
       " 'Pension Sherlock',\n",
       " 'Sharon Yang',\n",
       " 'HO Will',\n",
       " 'Ray Hsiao',\n",
       " 'Chiang Fred',\n",
       " 'Lily Wang',\n",
       " 'Yi Ting Chen',\n",
       " '劉靖宇',\n",
       " '劉靖宇',\n",
       " 'Ben Chen',\n",
       " 'Ben Chen',\n",
       " 'Chang Ching Chi',\n",
       " 'Gary Lai',\n",
       " '陳佐',\n",
       " 'HO Will',\n",
       " '鄭瑪答',\n",
       " 'Peter Quill',\n",
       " '陳瑞典',\n",
       " 'Lonsen Shen',\n",
       " 'Tony Hsieh',\n",
       " '劉靖宇',\n",
       " '吳宇崴',\n",
       " '張時杰']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_good_urllist(urllist):\n",
    "    \n",
    "    output = []\n",
    "\n",
    "#     profile = webdriver.FirefoxProfile()\n",
    "#     profile.set_preference(\"dom.webnotifications.enabled\", False)\n",
    "#     profile.update_preferences()\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"http://www.facebook.com\")\n",
    "    driver.find_element_by_id(\"email\").send_keys(USERNAME) # 將USERNAME改為你的臉書帳號\n",
    "    driver.find_element_by_id(\"pass\").send_keys(PASSWORD) # 將PASSWORD改為你的臉書帳號\n",
    "    driver.find_element_by_id(\"loginbutton\").click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    for url in urllist:\n",
    "        driver.get('http://www.facebook.com/' + url)\n",
    "        htmltext = driver.page_source\n",
    "        soup = BeautifulSoup(htmltext, 'html.parser')\n",
    "        for raw_text in soup.select('li[class=\"_5i_q\"]'):\n",
    "            output += re.findall(re.compile('aria-label=\"(.*?)\" class=\"_s'),str(raw_text))            \n",
    "\n",
    "    driver.close()\n",
    "    return output\n",
    "\n",
    "emoji_replies = parse_good_urllist(good_urllist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def tidy_up_data(post_persons, comment_persons, emoji_persons):\n",
    "    \n",
    "    all_persons = list(set(post_persons+comment_persons+emoji_persons))\n",
    "    post_times = []\n",
    "    comment_times = []\n",
    "    emoji_times = []\n",
    "    \n",
    "    for p in all_persons:\n",
    "        post_times.append(post_persons.count(p))\n",
    "        comment_times.append(comment_persons.count(p))\n",
    "        emoji_times.append(emoji_persons.count(p))\n",
    "    \n",
    "    return pd.DataFrame({'成員ID':all_persons, '貼文次數':post_times, '回文次數':comment_times, '回覆表情符號次數':emoji_times})\n",
    "        \n",
    "df = tidy_up_data(post_persons, comment_persons, emoji_replies)\n",
    "# df.to_excel('member_activity.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('member_activity.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
