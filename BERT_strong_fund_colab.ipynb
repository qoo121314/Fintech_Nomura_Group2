{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "新版seg BERT_strong_fund.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "doNFRjPqiBhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ae83a0a4-9b03-4307-e26f-a16f5298a81b"
      },
      "source": [
        "!pip install -q keras-bert\n",
        "!wget -q https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip\n",
        "!unzip -o chinese_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Archive:  chinese_L-12_H-768_A-12.zip\n",
            "   creating: chinese_L-12_H-768_A-12/\n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: chinese_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzoFRUGmh6a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQ_LEN = 512\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQ8UtquieFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pretrained_path = 'chinese_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMWc7HGsurZ8",
        "colab_type": "text"
      },
      "source": [
        "# 讀取seg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0KIY80RuoY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a561d8e5-ff45-44ec-abf6-9d8ee3710186"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-LE9l1-vHyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "from glob import glob \n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5iAo3QRuq3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_pickle('../content/drive/My Drive/Nomura/strong_data_finaltidy.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdE-iDkZvNPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = pd.read_csv('../content/drive/My Drive/Nomura/nomura_redemp_taiwan.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmxuHyaGvVo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb4c231e-26d4-469a-c8bd-cb173784233c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_index</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>time</th>\n",
              "      <th>author</th>\n",
              "      <th>articles_no_author</th>\n",
              "      <th>from</th>\n",
              "      <th>author_identity</th>\n",
              "      <th>author_enroll_time</th>\n",
              "      <th>word_sentence_list</th>\n",
              "      <th>seg</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>有一檔利安越南基金喔可以試試看</td>\n",
              "      <td>Re: 有人投資過越南基金嗎?</td>\n",
              "      <td>2011-01-01 22:34:00</td>\n",
              "      <td>8d8d</td>\n",
              "      <td>\"725\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>天使人</td>\n",
              "      <td>\"2010-12-10 09:48\"</td>\n",
              "      <td>[\", 有, 一, 檔, 利安, 越南, 基金, 喔, 可以, 試試, 看, \"]</td>\n",
              "      <td>[\", 檔, 利安, 越南, 基金, 喔, 試試, \"]</td>\n",
              "      <td>2011-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>利安越南基金可以在先鋒投顧的平台上買到但只有新幣計價的選擇而且績效很差　大盤漲　基金不見得會...</td>\n",
              "      <td>Re: 有人投資過越南基金嗎?</td>\n",
              "      <td>2011-01-01 22:37:00</td>\n",
              "      <td>fundhot</td>\n",
              "      <td>\"7483\"</td>\n",
              "      <td>\"我是強大\"</td>\n",
              "      <td>管理員</td>\n",
              "      <td>\"2010-12-10 09:47\"</td>\n",
              "      <td>[\", 利安, 越南, 基金, 可以, 在, 先鋒, 投顧, 的, 平台, 上, 買到, 但...</td>\n",
              "      <td>[\", 利安, 越南, 基金, 先鋒, 投顧, 平台, 買到, 新幣, 計價, 選擇, 績效...</td>\n",
              "      <td>2011-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>如果出口的力道逐漸復甦科技股應該還是會是重頭戲吧</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 16:14:00</td>\n",
              "      <td>king</td>\n",
              "      <td>\"964\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>天使人</td>\n",
              "      <td>\"2010-12-10 09:37\"</td>\n",
              "      <td>[\", 如果, 出口, 的, 力道, 逐漸, 復甦, 科技股, 應該, 還是, 會, 是, ...</td>\n",
              "      <td>[\", 出口, 力道, 逐漸, 復甦, 科技股, 應該, 會, 重頭戲, \"]</td>\n",
              "      <td>2011-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>發問的大大能否請問你傳產賺到錢的是哪一檔基金阿?另請問強基金大大推薦統一大滿貫/群益葛萊美/...</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 16:27:00</td>\n",
              "      <td>ryoma</td>\n",
              "      <td>\"634\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>名人堂成員 兼 分版版主</td>\n",
              "      <td>\"2011-01-03 16:18\"</td>\n",
              "      <td>[\", 發問, 的, 大大, 能否, 請問, 你, 傳產, 賺到, 錢, 的, 是, 哪, ...</td>\n",
              "      <td>[\", 發問, 大大, 請問, 傳產, 賺到, 錢, 檔, 基金, 請問, 強, 基金, 大...</td>\n",
              "      <td>2011-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>@chenyu今年強基金很看好台股上萬點推升力道來自國外的熱錢炒作的題材當然就是ECFA連香...</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 17:47:00</td>\n",
              "      <td>fundhot</td>\n",
              "      <td>\"7483\"</td>\n",
              "      <td>\"我是強大\"</td>\n",
              "      <td>管理員</td>\n",
              "      <td>\"2010-12-10 09:47\"</td>\n",
              "      <td>[\"@chenyu, 今年, 強, 基金, 很, 看好, 台股, 上萬, 點, 推升, 力道...</td>\n",
              "      <td>[\"@chenyu, 今年, 強, 基金, 看好, 台股, 上萬, 點, 推升, 力道, 國...</td>\n",
              "      <td>2011-01-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_index  ...        date\n",
              "0             10  ...  2011-01-01\n",
              "1             10  ...  2011-01-01\n",
              "2             11  ...  2011-01-03\n",
              "3             11  ...  2011-01-03\n",
              "4             11  ...  2011-01-03\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BOjjV4HvlWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e73e65e4-9a09-4525-ce6f-06d7c557077e"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ym</th>\n",
              "      <th>redemption</th>\n",
              "      <th>delta</th>\n",
              "      <th>signal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014-11-30</td>\n",
              "      <td>0.039739</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-12-31</td>\n",
              "      <td>0.041614</td>\n",
              "      <td>0.001875</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-02-28</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-03-31</td>\n",
              "      <td>0.081560</td>\n",
              "      <td>0.040514</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ym  redemption     delta  signal\n",
              "0  2014-11-30    0.039739       NaN   False\n",
              "1  2014-12-31    0.041614  0.001875    True\n",
              "2  2015-01-31    0.041046 -0.000568   False\n",
              "3  2015-02-28    0.041046  0.000000   False\n",
              "4  2015-03-31    0.081560  0.040514    True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LELC8PsCxhrX",
        "colab_type": "text"
      },
      "source": [
        "# 加入stopwords字典"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcYhFkdixpl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_sentence_list = df['seg']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPvDA22zxhy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopWords=[]\n",
        "with open('../content/drive/My Drive/Nomura/stopword.txt', 'r', encoding='UTF-8') as file:\n",
        "    for data in file.readlines():\n",
        "        data = data.strip()\n",
        "        stopWords.append(data)\n",
        "        remainder_sentence = []\n",
        "\n",
        "stopWords.append('\\n')\n",
        "apndix = ['(', '61', '.231', '.', '200', '.', '192', ' ', '臺灣', ')', ' ', '05', '/', '01', '/', '2020', ' ', '15', ':', '34', ':', '14\\n',  '--\\n', '※ '  ]\n",
        "for i in apndix:\n",
        "    stopWords.append(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbPzkphYx2wG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in word_sentence_list:\n",
        "    remainderWords = list(filter(lambda a: a not in stopWords and a != '\\n', i))\n",
        "    remainder_sentence.append(remainderWords)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRRVeOrfyeRR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1b42a601-6f8f-45b7-d837-0ab2f2513035"
      },
      "source": [
        "print(remainder_sentence[0:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['\"', '檔', '利安', '越南', '基金', '喔', '試試', '\"'], ['\"', '利安', '越南', '基金', '先鋒', '投顧', '平台', '買到', '新幣', '計價', '選擇', '績效', '差', '\\u3000', '大盤', '漲', '\\u3000', '基金', '不見得', '會', '動強', '基金', '想', '投資', '越南', '找', '對應', '基金', '挺', '可惜', '\"']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9OuRoHdx8uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stoppedContend=[]\n",
        "for sentence in remainder_sentence:\n",
        "  stoppedContend.append(''.join(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA-51CiLxmpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e26958b-37d0-4dba-c1d3-c0e032aa3a78"
      },
      "source": [
        "print(stoppedContend[0:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\"檔利安越南基金喔試試\"', '\"利安越南基金先鋒投顧平台買到新幣計價選擇績效差\\u3000大盤漲\\u3000基金不見得會動強基金想投資越南找對應基金挺可惜\"']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwnaRSiIzuD-",
        "colab_type": "text"
      },
      "source": [
        "# 整理資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl6TtcxtzJ25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['stopped_content']= stoppedContend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeEtY1ldwmR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70212b75-7783-4c63-e33b-c424553b5696"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_index</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>time</th>\n",
              "      <th>author</th>\n",
              "      <th>articles_no_author</th>\n",
              "      <th>from</th>\n",
              "      <th>author_identity</th>\n",
              "      <th>author_enroll_time</th>\n",
              "      <th>word_sentence_list</th>\n",
              "      <th>seg</th>\n",
              "      <th>date</th>\n",
              "      <th>stopped_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>有一檔利安越南基金喔可以試試看</td>\n",
              "      <td>Re: 有人投資過越南基金嗎?</td>\n",
              "      <td>2011-01-01 22:34:00</td>\n",
              "      <td>8d8d</td>\n",
              "      <td>\"725\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>天使人</td>\n",
              "      <td>\"2010-12-10 09:48\"</td>\n",
              "      <td>[\", 有, 一, 檔, 利安, 越南, 基金, 喔, 可以, 試試, 看, \"]</td>\n",
              "      <td>[\", 檔, 利安, 越南, 基金, 喔, 試試, \"]</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>\"檔利安越南基金喔試試\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>利安越南基金可以在先鋒投顧的平台上買到但只有新幣計價的選擇而且績效很差　大盤漲　基金不見得會...</td>\n",
              "      <td>Re: 有人投資過越南基金嗎?</td>\n",
              "      <td>2011-01-01 22:37:00</td>\n",
              "      <td>fundhot</td>\n",
              "      <td>\"7483\"</td>\n",
              "      <td>\"我是強大\"</td>\n",
              "      <td>管理員</td>\n",
              "      <td>\"2010-12-10 09:47\"</td>\n",
              "      <td>[\", 利安, 越南, 基金, 可以, 在, 先鋒, 投顧, 的, 平台, 上, 買到, 但...</td>\n",
              "      <td>[\", 利安, 越南, 基金, 先鋒, 投顧, 平台, 買到, 新幣, 計價, 選擇, 績效...</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>\"利安越南基金先鋒投顧平台買到新幣計價選擇績效差　大盤漲　基金不見得會動強基金想投資越南找對...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>如果出口的力道逐漸復甦科技股應該還是會是重頭戲吧</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 16:14:00</td>\n",
              "      <td>king</td>\n",
              "      <td>\"964\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>天使人</td>\n",
              "      <td>\"2010-12-10 09:37\"</td>\n",
              "      <td>[\", 如果, 出口, 的, 力道, 逐漸, 復甦, 科技股, 應該, 還是, 會, 是, ...</td>\n",
              "      <td>[\", 出口, 力道, 逐漸, 復甦, 科技股, 應該, 會, 重頭戲, \"]</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>\"出口力道逐漸復甦科技股應該會重頭戲\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>發問的大大能否請問你傳產賺到錢的是哪一檔基金阿?另請問強基金大大推薦統一大滿貫/群益葛萊美/...</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 16:27:00</td>\n",
              "      <td>ryoma</td>\n",
              "      <td>\"634\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>名人堂成員 兼 分版版主</td>\n",
              "      <td>\"2011-01-03 16:18\"</td>\n",
              "      <td>[\", 發問, 的, 大大, 能否, 請問, 你, 傳產, 賺到, 錢, 的, 是, 哪, ...</td>\n",
              "      <td>[\", 發問, 大大, 請問, 傳產, 賺到, 錢, 檔, 基金, 請問, 強, 基金, 大...</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>\"發問大大請問傳產賺到錢檔基金請問強基金大大推薦統一大滿貫群益葛萊美保德信高成長原因\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>@chenyu今年強基金很看好台股上萬點推升力道來自國外的熱錢炒作的題材當然就是ECFA連香...</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 17:47:00</td>\n",
              "      <td>fundhot</td>\n",
              "      <td>\"7483\"</td>\n",
              "      <td>\"我是強大\"</td>\n",
              "      <td>管理員</td>\n",
              "      <td>\"2010-12-10 09:47\"</td>\n",
              "      <td>[\"@chenyu, 今年, 強, 基金, 很, 看好, 台股, 上萬, 點, 推升, 力道...</td>\n",
              "      <td>[\"@chenyu, 今年, 強, 基金, 看好, 台股, 上萬, 點, 推升, 力道, 國...</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>\"@chenyu今年強基金看好台股上萬點推升力道國外熱錢炒作題材ECFA香港股神曹仁超說EC...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_index  ...                                    stopped_content\n",
              "0             10  ...                                       \"檔利安越南基金喔試試\"\n",
              "1             10  ...  \"利安越南基金先鋒投顧平台買到新幣計價選擇績效差　大盤漲　基金不見得會動強基金想投資越南找對...\n",
              "2             11  ...                                \"出口力道逐漸復甦科技股應該會重頭戲\"\n",
              "3             11  ...        \"發問大大請問傳產賺到錢檔基金請問強基金大大推薦統一大滿貫群益葛萊美保德信高成長原因\"\n",
              "4             11  ...  \"@chenyu今年強基金看好台股上萬點推升力道國外熱錢炒作題材ECFA香港股神曹仁超說EC...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aICOjWXywt3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.tseries.offsets import MonthEnd\n",
        "df['time'] = pd.to_datetime(df['time'])\n",
        "df['EndOfMonth'] = pd.to_datetime(df['time'], format=\"%Y%m\") + MonthEnd(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbud6g6vw2pl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73435e97-183e-439c-8e4e-2547594684ae"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_index</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>time</th>\n",
              "      <th>author</th>\n",
              "      <th>articles_no_author</th>\n",
              "      <th>from</th>\n",
              "      <th>author_identity</th>\n",
              "      <th>author_enroll_time</th>\n",
              "      <th>word_sentence_list</th>\n",
              "      <th>seg</th>\n",
              "      <th>date</th>\n",
              "      <th>stopped_content</th>\n",
              "      <th>EndOfMonth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>有一檔利安越南基金喔可以試試看</td>\n",
              "      <td>Re: 有人投資過越南基金嗎?</td>\n",
              "      <td>2011-01-01 22:34:00</td>\n",
              "      <td>8d8d</td>\n",
              "      <td>\"725\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>天使人</td>\n",
              "      <td>\"2010-12-10 09:48\"</td>\n",
              "      <td>[\", 有, 一, 檔, 利安, 越南, 基金, 喔, 可以, 試試, 看, \"]</td>\n",
              "      <td>[\", 檔, 利安, 越南, 基金, 喔, 試試, \"]</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>\"檔利安越南基金喔試試\"</td>\n",
              "      <td>2011-01-31 22:34:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>利安越南基金可以在先鋒投顧的平台上買到但只有新幣計價的選擇而且績效很差　大盤漲　基金不見得會...</td>\n",
              "      <td>Re: 有人投資過越南基金嗎?</td>\n",
              "      <td>2011-01-01 22:37:00</td>\n",
              "      <td>fundhot</td>\n",
              "      <td>\"7483\"</td>\n",
              "      <td>\"我是強大\"</td>\n",
              "      <td>管理員</td>\n",
              "      <td>\"2010-12-10 09:47\"</td>\n",
              "      <td>[\", 利安, 越南, 基金, 可以, 在, 先鋒, 投顧, 的, 平台, 上, 買到, 但...</td>\n",
              "      <td>[\", 利安, 越南, 基金, 先鋒, 投顧, 平台, 買到, 新幣, 計價, 選擇, 績效...</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>\"利安越南基金先鋒投顧平台買到新幣計價選擇績效差　大盤漲　基金不見得會動強基金想投資越南找對...</td>\n",
              "      <td>2011-01-31 22:37:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>如果出口的力道逐漸復甦科技股應該還是會是重頭戲吧</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 16:14:00</td>\n",
              "      <td>king</td>\n",
              "      <td>\"964\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>天使人</td>\n",
              "      <td>\"2010-12-10 09:37\"</td>\n",
              "      <td>[\", 如果, 出口, 的, 力道, 逐漸, 復甦, 科技股, 應該, 還是, 會, 是, ...</td>\n",
              "      <td>[\", 出口, 力道, 逐漸, 復甦, 科技股, 應該, 會, 重頭戲, \"]</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>\"出口力道逐漸復甦科技股應該會重頭戲\"</td>\n",
              "      <td>2011-01-31 16:14:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>發問的大大能否請問你傳產賺到錢的是哪一檔基金阿?另請問強基金大大推薦統一大滿貫/群益葛萊美/...</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 16:27:00</td>\n",
              "      <td>ryoma</td>\n",
              "      <td>\"634\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>名人堂成員 兼 分版版主</td>\n",
              "      <td>\"2011-01-03 16:18\"</td>\n",
              "      <td>[\", 發問, 的, 大大, 能否, 請問, 你, 傳產, 賺到, 錢, 的, 是, 哪, ...</td>\n",
              "      <td>[\", 發問, 大大, 請問, 傳產, 賺到, 錢, 檔, 基金, 請問, 強, 基金, 大...</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>\"發問大大請問傳產賺到錢檔基金請問強基金大大推薦統一大滿貫群益葛萊美保德信高成長原因\"</td>\n",
              "      <td>2011-01-31 16:27:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>@chenyu今年強基金很看好台股上萬點推升力道來自國外的熱錢炒作的題材當然就是ECFA連香...</td>\n",
              "      <td>Re: 今年的台股基金投資方向</td>\n",
              "      <td>2011-01-03 17:47:00</td>\n",
              "      <td>fundhot</td>\n",
              "      <td>\"7483\"</td>\n",
              "      <td>\"我是強大\"</td>\n",
              "      <td>管理員</td>\n",
              "      <td>\"2010-12-10 09:47\"</td>\n",
              "      <td>[\"@chenyu, 今年, 強, 基金, 很, 看好, 台股, 上萬, 點, 推升, 力道...</td>\n",
              "      <td>[\"@chenyu, 今年, 強, 基金, 看好, 台股, 上萬, 點, 推升, 力道, 國...</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>\"@chenyu今年強基金看好台股上萬點推升力道國外熱錢炒作題材ECFA香港股神曹仁超說EC...</td>\n",
              "      <td>2011-01-31 17:47:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_index  ...          EndOfMonth\n",
              "0             10  ... 2011-01-31 22:34:00\n",
              "1             10  ... 2011-01-31 22:37:00\n",
              "2             11  ... 2011-01-31 16:14:00\n",
              "3             11  ... 2011-01-31 16:27:00\n",
              "4             11  ... 2011-01-31 17:47:00\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU6YaOzXzg98",
        "colab_type": "text"
      },
      "source": [
        "# 資料合併"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9_buUFtz5vN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['EndOfMonth'] = df['EndOfMonth'].apply(lambda x:x.date())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYapG0zfzXKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "1ce6fcf3-8d73-423c-c6d0-bc39bbc1e55b"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ym</th>\n",
              "      <th>redemption</th>\n",
              "      <th>delta</th>\n",
              "      <th>signal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014-11-30</td>\n",
              "      <td>0.039739</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-12-31</td>\n",
              "      <td>0.041614</td>\n",
              "      <td>0.001875</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-02-28</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-03-31</td>\n",
              "      <td>0.081560</td>\n",
              "      <td>0.040514</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ym  redemption     delta  signal\n",
              "0  2014-11-30    0.039739       NaN   False\n",
              "1  2014-12-31    0.041614  0.001875    True\n",
              "2  2015-01-31    0.041046 -0.000568   False\n",
              "3  2015-02-28    0.041046  0.000000   False\n",
              "4  2015-03-31    0.081560  0.040514    True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZOf0ge-0jgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y['ym'] = pd.to_datetime(y['ym']).apply(lambda x:x.date())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd38esWbzi91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = df.merge(y,   left_on='EndOfMonth',right_on='ym')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVTPNxOyj4HJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6864cb83-2a25-443a-b01c-75467923513a"
      },
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "# BERT 透過 Subword 的方式讓辭典長度最大就是 30522\n",
        "token_dict = {}\n",
        "with open(vocab_path, 'r', encoding='utf8') as f:\n",
        "    for line in f.readlines():\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "print(\"辭典長度:\", len(token_dict))\n",
        "\n",
        "\n",
        "model = load_trained_model_from_checkpoint(\n",
        "    config_path,\n",
        "    checkpoint_path,\n",
        "    training=False,\n",
        "    trainable=False,\n",
        "    seq_len=SEQ_LEN,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "辭典長度: 21128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rePlRX0vYH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYj4FDb-UaSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_bert import Tokenizer\n",
        "tokenizer = Tokenizer(token_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6L1yEAcweOn",
        "colab_type": "text"
      },
      "source": [
        "# 整理成可跑型態"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U8r2wj11Vtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb8fdcb7-f242-4fa9-e629-66cb0fd28bfe"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_index</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>time</th>\n",
              "      <th>author</th>\n",
              "      <th>articles_no_author</th>\n",
              "      <th>from</th>\n",
              "      <th>author_identity</th>\n",
              "      <th>author_enroll_time</th>\n",
              "      <th>word_sentence_list</th>\n",
              "      <th>seg</th>\n",
              "      <th>date</th>\n",
              "      <th>stopped_content</th>\n",
              "      <th>EndOfMonth</th>\n",
              "      <th>ym</th>\n",
              "      <th>redemption</th>\n",
              "      <th>delta</th>\n",
              "      <th>signal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>177</td>\n",
              "      <td>11:00 新台幣貶2.82角 報32.0元兌1美元鉅亨網新聞中心　　2015-01-05 ...</td>\n",
              "      <td>Re: 關於匯率避險</td>\n",
              "      <td>2015-01-05 11:58:00</td>\n",
              "      <td>baonamy</td>\n",
              "      <td>\"823\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>名人堂成員</td>\n",
              "      <td>\"2011-01-16 23:00\"</td>\n",
              "      <td>[\", 11:00,  , 新台幣, 貶, 2.82, 角,  , 報, 32.0, 元, ...</td>\n",
              "      <td>[\", 11:00,  , 新台幣, 貶, 2.82, 角,  , 報, 32.0, 元, ...</td>\n",
              "      <td>2015-01-05</td>\n",
              "      <td>\"11:00新台幣貶2.82角報32.0元兌美元鉅亨網新聞中心　　2015-01-05  1...</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>177</td>\n",
              "      <td>有位單筆操作比我厲害好幾倍的大大問我對上証走勢的看法家庭主婦不敢拿水果刀當大刀耍倒是有個圖意...</td>\n",
              "      <td>Re: 關於匯率避險</td>\n",
              "      <td>2015-01-15 23:35:00</td>\n",
              "      <td>Ivy</td>\n",
              "      <td>\"2373\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>名人堂成員</td>\n",
              "      <td>\"2012-10-08 19:52\"</td>\n",
              "      <td>[\", 有, 位, 單, 筆, 操作, 比, 我, 厲害, 好幾, 倍, 的, 大大, 問,...</td>\n",
              "      <td>[\", 位, 單, 筆, 操作, 厲害, 好幾, 倍, 大大, 問, 上証, 走勢, 看法,...</td>\n",
              "      <td>2015-01-15</td>\n",
              "      <td>\"位單筆操作厲害好幾倍大大問上証走勢看法家庭主婦敢水果刀大刀耍倒是圖意圖透露給一點兒訊息\"</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>177</td>\n",
              "      <td>不知道匯率目前該存啥比較好 現在還是主要存美元 等歐元看真ㄉ有沒有1:1以下可以撿(簡單又保...</td>\n",
              "      <td>Re: 關於匯率避險</td>\n",
              "      <td>2015-01-16 06:01:00</td>\n",
              "      <td>apple</td>\n",
              "      <td>\"81\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>註冊會員</td>\n",
              "      <td>\"2012-04-02 22:40\"</td>\n",
              "      <td>[\", 不, 知道, 匯率, 目前, 該, 存, 啥, 比較, 好,  , 現在, 還是, ...</td>\n",
              "      <td>[\", 知道, 匯率, 目前, 存, 比較,  , 現在, 主要, 存, 美元,  , 歐元...</td>\n",
              "      <td>2015-01-16</td>\n",
              "      <td>\"知道匯率目前存比較現在主要存美元歐元真ㄉ沒有1:1以下撿簡單保比較安心\"</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>177</td>\n",
              "      <td>感謝ivy姐回覆，若依匯率KD來看，中線準備看升，短線準備看貶，基於中線保護短線，等短線回檔...</td>\n",
              "      <td>Re: 關於匯率避險</td>\n",
              "      <td>2015-01-16 10:11:00</td>\n",
              "      <td>simonks</td>\n",
              "      <td>\"960\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>名人堂成員</td>\n",
              "      <td>\"2013-02-24 21:01\"</td>\n",
              "      <td>[\", 感謝, ivy, 姐, 回覆, ，, 若, 依, 匯率, KD, 來, 看, ，, ...</td>\n",
              "      <td>[\", 感謝, ivy, 姐, 回覆, 匯率, KD, 中線, 準備, 看升, 短線, 準備...</td>\n",
              "      <td>2015-01-16</td>\n",
              "      <td>\"感謝ivy姐回覆匯率KD中線準備看升短線準備看貶中線保護短線短線回檔日kd死叉適時介入上證...</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>177</td>\n",
              "      <td>sorry沒注意到您有回這則個人看法是上證仍有機會受惠於年前逆回購及節慶消費價格是真實的,再...</td>\n",
              "      <td>Re: 關於匯率避險</td>\n",
              "      <td>2015-01-28 11:27:00</td>\n",
              "      <td>Ivy</td>\n",
              "      <td>\"2373\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>名人堂成員</td>\n",
              "      <td>\"2012-10-08 19:52\"</td>\n",
              "      <td>[\"sorry, 沒, 注意到, 您, 有, 回, 這, 則, 個人, 看法, 是, 上證,...</td>\n",
              "      <td>[\"sorry, 沒, 注意到, 回, 個人, 看法, 上證, 機會, 受惠, 年前, 逆,...</td>\n",
              "      <td>2015-01-28</td>\n",
              "      <td>\"sorry沒注意到回個人看法上證機會受惠年前逆回購節慶消費價格真實獻新圖美元人民幣美元台幣...</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>0.041046</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_index  ... signal\n",
              "0            177  ...  False\n",
              "1            177  ...  False\n",
              "2            177  ...  False\n",
              "3            177  ...  False\n",
              "4            177  ...  False\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zkf0rWj07EV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_array = (data['author_identity']==\"名人堂成員\") |  (data['author_identity']==\"管理員\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df24rUzw9h5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# index_array = data['type'].apply(lambda x: x not in (['新聞', '標的'])) \n",
        "# X=data[index_array ]['content'].iloc[0:100].apply(lambda x:tokenizer.encode(x, max_len=SEQ_LEN))\n",
        "traindata = data[index_array]\n",
        "indices=[]\n",
        "y=[]\n",
        "for content, label in zip(traindata['stopped_content'],traindata['signal'] ) :\n",
        "  ids, segments = tokenizer.encode(content, max_len=SEQ_LEN)\n",
        "  indices.append(ids)\n",
        "\n",
        "  y.append(label)\n",
        "\n",
        "# Y=data[index_array ]['label'].iloc[0:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQsMW85cHHsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [indices, np.zeros_like(indices)]\n",
        "# X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyfjxEsSCcY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "# Xdata = [a, np.zeros_like(a)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkSxob3NBsjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# en, seg = tokenizer.encode(a[0])\n",
        "# print(\"[Encoding]:\", en)\n",
        "# print(\"[Segement]:\", seg)\n",
        "# de = tokenizer.decode(a[0])\n",
        "# print(\"[Decode]:\", de)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCIDl3Kk3eNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data['stopped_content'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG4ihBnI2AJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPqV7Iq9zxZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 準備資料流\n",
        "# import glob\n",
        "# from tqdm import tqdm\n",
        "# import numpy as np\n",
        "\n",
        "# def load_data(path):\n",
        "#     global tokenizer\n",
        "#     indices, sentiments = [], []\n",
        "#     for folder, sentiment in (('neg', 0), ('pos', 1)):\n",
        "#         pat = glob.glob(\"{}/{}/*\".format(path, folder))\n",
        "#         for fn in tqdm(iter(pat), total=len(pat)):\n",
        "#             with open(fn, 'r', encoding=\"utf-8\") as f:\n",
        "#                   text = f.read()\n",
        "#             ids, segments = tokenizer.encode(text, max_len=SEQ_LEN)\n",
        "#             indices.append(ids)\n",
        "#             sentiments.append(sentiment)\n",
        "#     items = list(zip(indices, sentiments))\n",
        "#     np.random.shuffle(items)\n",
        "#     indices = np.array([i for i, s in items])\n",
        "#     sentiments = np.array([s for i, s in items])\n",
        "\n",
        "#     return [indices, np.zeros_like(indices)], np.array(sentiments)\n",
        "\n",
        "# # 讀取資料集\n",
        "# train_path = os.path.join(os.path.dirname(dataset), 'aclImdb', 'train')\n",
        "# test_path = os.path.join(os.path.dirname(dataset), 'aclImdb', 'test')\n",
        "\n",
        "# train_x, train_y = load_data(train_path)\n",
        "# test_x, test_y = load_data(test_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM42fhCWzxkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7485afe8-4c7d-4f12-9353-476166ef3670"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'simple_rnn_1/strided_slice_2:0' shape=(None, 64) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxbNGi5jzrs0",
        "colab_type": "text"
      },
      "source": [
        "# 跑模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhMA1j7wnqSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import SimpleRNN\n",
        "inputs = model.inputs[:2]\n",
        "x = SimpleRNN(64)(model.output)\n",
        "outputs = keras.layers.Dense(units=2, activation='softmax')(x)\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=\"adam\",\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mwTkptHNYr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b934e693-8743-4aab-8b52-836849ad0241"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 512, 768), ( 16226304    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 512, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 512, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 512, 768)     393216      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 512, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 512, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 512, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 512, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 512, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 512, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 512, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 512, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)        (None, 64)           53312       Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            130         simple_rnn_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 101,730,498\n",
            "Trainable params: 53,442\n",
            "Non-trainable params: 101,677,056\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZSipO99nCsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "f37704a5-2d57-490b-e1a7-538b6473c16c"
      },
      "source": [
        "import os\n",
        "\n",
        "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
        "\n",
        "# TF_KERAS must be added to environment variables in order to use TPU\n",
        "os.environ['TF_KERAS'] = '1'\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras_bert import get_custom_objects\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-dcf352542498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_custom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mTPU_WORKER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'grpc://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTPU_WORKER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgP7bCQxrZpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "9a0afbb0-40d4-42a5-ba77-c8ad7e78d54e"
      },
      "source": [
        "model.fit(\n",
        "    X,\n",
        "    y,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7103 samples, validate on 1776 samples\n",
            "Epoch 1/5\n",
            "7103/7103 [==============================] - 845s 119ms/step - loss: 0.6976 - sparse_categorical_accuracy: 0.5216 - val_loss: 0.7183 - val_sparse_categorical_accuracy: 0.4657\n",
            "Epoch 2/5\n",
            "7103/7103 [==============================] - 840s 118ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.5433 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.4690\n",
            "Epoch 3/5\n",
            "7103/7103 [==============================] - 840s 118ms/step - loss: 0.6779 - sparse_categorical_accuracy: 0.5643 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.5676\n",
            "Epoch 4/5\n",
            "7103/7103 [==============================] - 836s 118ms/step - loss: 0.6733 - sparse_categorical_accuracy: 0.5709 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.5619\n",
            "Epoch 5/5\n",
            "7103/7103 [==============================] - 836s 118ms/step - loss: 0.6580 - sparse_categorical_accuracy: 0.6100 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.5518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f48fd4fddd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfhEupur2LM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('bert_model_strongfund.h5') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rOr7svl2aNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('../content/drive/My Drive/Nomura/bert_model_strongfund.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGXP5BgB2zJ7",
        "colab_type": "text"
      },
      "source": [
        "# load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMwh0rac2xTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('my_model.h5')\n",
        "print('test after load: ', model.predict(X_test[0:2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBSba3vprlRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.evaluate(test_x, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}